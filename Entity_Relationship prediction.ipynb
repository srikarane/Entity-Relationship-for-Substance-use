{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1xb-YcHeOI82Hcwm6OtHZbFKKRCf_y0EJ","authorship_tag":"ABX9TyOpnK1hnoNHvQndMozp4p30"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1afa45bbc6b4453da77760f953d7706c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_965a85950441456cb9ce44446f8b4672","IPY_MODEL_e446e879a169416c93fee6a7abd126dc","IPY_MODEL_41b54eae93094dcaa7a6f5d81d9411cc"],"layout":"IPY_MODEL_3c4f370d730c475390ac14eb20511d8b"}},"965a85950441456cb9ce44446f8b4672":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6016b3e025f2416dbe100ec92482fd09","placeholder":"​","style":"IPY_MODEL_a4e3ec7c4b2244fa8f0da21a39369082","value":"pytorch_model.bin: 100%"}},"e446e879a169416c93fee6a7abd126dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c13ac382efd499ca13e25af58baf9e9","max":435778770,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aca9640ebff242e7a8e23537dd51a599","value":435778770}},"41b54eae93094dcaa7a6f5d81d9411cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3009c1de1c3f4dffabec97e71d0c177c","placeholder":"​","style":"IPY_MODEL_aec9b3d8cf71427189bb657d3fa1cc8c","value":" 436M/436M [00:13&lt;00:00, 31.2MB/s]"}},"3c4f370d730c475390ac14eb20511d8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6016b3e025f2416dbe100ec92482fd09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4e3ec7c4b2244fa8f0da21a39369082":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c13ac382efd499ca13e25af58baf9e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aca9640ebff242e7a8e23537dd51a599":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3009c1de1c3f4dffabec97e71d0c177c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aec9b3d8cf71427189bb657d3fa1cc8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Entity, Relations prediction.\n","**Description**\n","\n","\n","1.   Loads Ner and relation models.\n","2.   Given a sentence predicts entities , roles, status and methods.\n","3.  Identifies and extracts spans from above category predictions having continuous labels with a tolerance of max internal gap of 1.\n","4.  Generates span pairs from the predictive data, mapping entities to  Role, Status, and Method.\n","5.  Inserts span markers according to span pairs and positions of it.Entity spans are marked with [SPAN1_START] and [SPAN1_END]. Role spans are marked with [SPAN2_START] and [SPAN2_END]\n","6.  These span pairs serve as inputs to the relation model, which then predicts the relationships between them.\n","\n","Prediction output is data frame containing text with span markers, entity, role/Status/method and the relation prediction.\n","\n"],"metadata":{"id":"92mSdUoTRqf8"}},{"cell_type":"code","source":["import json\n","import pandas as pd\n","\n","from transformers import BertTokenizerFast, BertModel, AdamW, get_linear_schedule_with_warmup, DataCollatorForTokenClassification\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.metrics import classification_report\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn.utils.rnn import pad_sequence\n","device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","import itertools"],"metadata":{"id":"WwAWsWzZw50p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_type='Flt_ent_role_model'\n","ver=2\n","\n","txt='SOCIAL HISTORY:  The patient is retired. He is married. He had 4 children. He quite smoking 25 years ago after a 35-year history of smoking. He does not drink alcohol.'"],"metadata":{"id":"EPqKtq5Yw0wL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E3oNg98usykw"},"outputs":[],"source":["id_label_status={0:'O',1:'B-Status',2:'I-Status'}\n","id_label_method={0:'O',1:'B-Method',2:'I-Method'}\n","id_label_role={0:'O',1:'B-Type',2:'I-Type',3:'B-Amount',4:'I-Amount',5:'B-Temporal',6:'I-Temporal',7:'B-Frequency',8:'I-Frequency',9:'B-QuitHistory',10:'I-QuitHistory',11:'B-ExposureHistory',12:'I-ExposureHistory',13:'B-Location',14:'I-Location'}\n","id_label_event={0:'No Relation',1:'Relation'}\n","label_id_status = {v: k for k, v in id_label_status.items()}\n","label_id_method = {v: k for k, v in id_label_method.items()}\n","label_id_role = {v: k for k, v in id_label_role.items()}\n","label_id_ent = {'B-Alcohol':1,\n"," 'B-Drug':3,\n"," 'B-Family':5,\n"," 'B-Tobacco':7,\n"," 'I-Alcohol':2,\n"," 'I-Drug':4,\n"," 'I-Family':6,\n"," 'I-Tobacco':8,\n"," 'O':0}\n","id_label_ent = {v: k for k, v in label_id_ent.items()}\n","label_id_event = {v: k for k, v in id_label_event.items()}\n","num_freeze_layers=6\n","max_len=512\n","bert_model_name='emilyalsentzer/Bio_ClinicalBERT'\n","tokenizer = BertTokenizerFast.from_pretrained(bert_model_name)\n","ner_model_path='/content/drive/MyDrive/PHD_assessment_gmu/models/final_models/'+model_type+'_'+str(ver)+'.pth'\n","rel_classifier_pth='/content/drive/MyDrive/PHD_assessment_gmu/models/final_models/Indepent_relation_classifier_v6/'"]},{"cell_type":"markdown","source":["# Model Loading"],"metadata":{"id":"5jtnm_J_uLfn"}},{"cell_type":"markdown","source":["## Ner Model"],"metadata":{"id":"s7uf0_K3uRNg"}},{"cell_type":"code","source":["class EntityBertModel(nn.Module):\n","  def __init__(self, model_name, num_freeze_layers,num_status_labels,num_method_labels,num_role_labels,num_entity_labels, dropout=0.1):\n","    super(EntityBertModel, self).__init__()\n","    self.bertmodel = BertModel.from_pretrained(model_name)\n","    #Performing freezing bert layers\n","    for layer in self.bertmodel.encoder.layer[:num_freeze_layers]:\n","      for param in layer.parameters():\n","          param.requires_grad = False\n","    self.dropout = nn.Dropout(dropout)\n","    self.status_classifier = nn.Linear(self.bertmodel.config.hidden_size, num_status_labels)\n","    self.method_classifier = nn.Linear(self.bertmodel.config.hidden_size, num_method_labels)\n","    self.role_classifier = nn.Linear(self.bertmodel.config.hidden_size, num_role_labels)\n","    self.entity_classifier = nn.Linear(self.bertmodel.config.hidden_size, num_entity_labels)\n","  def forward(self, input_ids, attention_mask):\n","    bert_output = self.bertmodel(input_ids=input_ids, attention_mask=attention_mask)\n","    sequence_output = self.dropout(bert_output[0])\n","    status_logits = self.status_classifier(sequence_output)\n","    method_logits = self.method_classifier(sequence_output)\n","    role_logits = self.role_classifier(sequence_output)\n","    entity_logits = self.entity_classifier(sequence_output)\n","\n","    return status_logits, method_logits, role_logits, entity_logits\n"],"metadata":{"id":"_24mY9m5tEVk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ner_model= EntityBertModel(model_name=bert_model_name,num_freeze_layers=num_freeze_layers,num_status_labels=len(id_label_status),num_method_labels=len(id_label_method),num_role_labels=len(id_label_role),num_entity_labels=len(id_label_ent))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["1afa45bbc6b4453da77760f953d7706c","965a85950441456cb9ce44446f8b4672","e446e879a169416c93fee6a7abd126dc","41b54eae93094dcaa7a6f5d81d9411cc","3c4f370d730c475390ac14eb20511d8b","6016b3e025f2416dbe100ec92482fd09","a4e3ec7c4b2244fa8f0da21a39369082","4c13ac382efd499ca13e25af58baf9e9","aca9640ebff242e7a8e23537dd51a599","3009c1de1c3f4dffabec97e71d0c177c","aec9b3d8cf71427189bb657d3fa1cc8c"]},"id":"Q21i2oYPtder","executionInfo":{"status":"ok","timestamp":1707245611457,"user_tz":300,"elapsed":18719,"user":{"displayName":"srikaran elakurthy","userId":"10476685350926501647"}},"outputId":"288866d1-c260-42ec-bab3-2891c7e3179f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1afa45bbc6b4453da77760f953d7706c"}},"metadata":{}}]},{"cell_type":"code","source":["ner_model.load_state_dict(torch.load(ner_model_path,map_location=device))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ejkTttottgFE","executionInfo":{"status":"ok","timestamp":1707245798504,"user_tz":300,"elapsed":7317,"user":{"displayName":"srikaran elakurthy","userId":"10476685350926501647"}},"outputId":"ae579abc-3936-4fc9-d03b-a525e15d9d74"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## Relation Model"],"metadata":{"id":"d9Hm75KeuVfT"}},{"cell_type":"markdown","source":["### Extracting spans and forming span pairs and predicting relations"],"metadata":{"id":"f2Ym7OQmuZm3"}},{"cell_type":"code","source":["def extract_spans_from_labels(labels):\n","    #Span: Having continous labels with a tolerance for a maximum internal gap of one 'O'.\n","    #Extracting spans from labels\n","    #Outputs: comprising a list of span tuples. Each tuple encapsulates the category of the span as well as the range of token indices that constitute the span.\n","    spans = []\n","    current_span = []\n","    current_label = None\n","    last_valid_index = -1  # Tracks the last index of a non-'O' label\n","\n","    for i, label in enumerate(labels):\n","        # Ignore BIO scheme and consider only the entity type\n","        simplified_label = label[2:] if label.startswith(('B-', 'I-')) else label\n","\n","        # Start a new span or continue the current one\n","        if simplified_label != 'O':\n","            # If starting a new span or within allowable break from last non-'O'\n","            if current_label is None or simplified_label != current_label or i - last_valid_index > 2:\n","                # Save the current span before starting a new one and reset the current span\n","                if current_span:\n","                    spans.append((current_label, current_span))\n","                    current_span = []\n","                current_label = simplified_label\n","            current_span.append(i)\n","            last_valid_index = i\n","        elif current_span and i - last_valid_index > 3:\n","            # End the current span if the break is too long\n","            spans.append((current_label, current_span))\n","            current_span = []\n","            current_label = None\n","\n","    # Add the last span if exists\n","    if current_span:\n","        spans.append((current_label, current_span))\n","\n","    return spans\n","def insert_span_markers(text, spans):\n","    '''\n","    Inserts span markers for entity and role in the text.\n","    Entity spans are marked with [SPAN1_START] and [SPAN1_END]\n","    Role spans are marked with [SPAN2_START] and [SPAN2_END]\n","    Outputs: text with span markers inserted in the correct positions.\n","    '''\n","    # Create a list to store the markers that need to be inserted at each index\n","    insertions = {i: [] for i in range(len(text) + 1)}\n","\n","    # Populate the insertions dictionary with the correct markers for each span\n","    for span in spans:\n","        start, end, category = span\n","        if category == 'entity':\n","            insertions[start].append('[SPAN1_START]')\n","            insertions[end].append('[SPAN1_END]')\n","        elif category == 'role':\n","            insertions[start].append('[SPAN2_START]')\n","            insertions[end].append('[SPAN2_END]')\n","\n","    # Construct the new text with markers\n","    new_text_pieces = []\n","    for i, char in enumerate(text):\n","        # Add markers before the current character\n","        if insertions[i]:\n","            new_text_pieces.append(' '+' '.join(insertions[i]) + ' ')\n","        new_text_pieces.append(char)\n","    # Add any markers that should be inserted after the last character\n","    if insertions[len(text)]:\n","        new_text_pieces.append(' ' + ' '.join(insertions[len(text)]))\n","\n","    # Join all pieces of the new text\n","    return ''.join(new_text_pieces)\n","\n","def correct_span_positions(span_pos):\n","  '''\n","  Transforms a list of sequential token indices within a span into a concise range representation.\n","  '''\n","  updated_span_pos=[]\n","  for ele in span_pos:\n","    #Handling for span having only 1 token\n","    if len(ele[1])==1:\n","      updated_span_pos.append((ele[0],(ele[1][0],ele[1][0])))\n","    elif len(ele[1])>=2:\n","      strt_pos=ele[1][0]\n","      end_pos=ele[1][-1]\n","      updated_span_pos.append((ele[0],(ele[1][0],ele[1][-1])))\n","  return updated_span_pos\n","def convert_id_label(prediction_data,id_label):\n","  prediction_data=[id_label[ele] for ele in prediction_data]\n","  return prediction_data\n","def generate_prediction_spans(prediction_data_ent,prediction_data_role,prediction_data_status,prediction_data_method,id_label_ent,id_label_method,id_label_role,id_label_status):\n","  '''\n","  Generate spans from the prediction data.\n","  Generates span pairs from the predictive data, mapping entities to  Role, Status, and Method.\n","  Outputs: Relation pairs dict (key as relation pair((entity,offsetpositions),(role,offsetposotions)) and value as relation label)\n","           and spans for entity, role, status, and method.\n","  '''\n","  prediction_data_ent=convert_id_label(prediction_data_ent,id_label_ent)\n","  prediction_data_role=convert_id_label(prediction_data_role,id_label_role)\n","  prediction_data_method=convert_id_label(prediction_data_method,id_label_method)\n","  prediction_data_status=convert_id_label(prediction_data_status,id_label_status)\n","  #Extracts spans from the prediction data\n","  pred_spans_ent=extract_spans_from_labels(prediction_data_ent)\n","  pred_spans_roles=extract_spans_from_labels(prediction_data_role)\n","  pred_spans_status=extract_spans_from_labels(prediction_data_status)\n","  pred_spans_method=extract_spans_from_labels(prediction_data_method)\n","  #Transforms a list of sequential token indices within a span into a concise range representation.\n","  pred_spans_ent=correct_span_positions(pred_spans_ent)\n","  pred_spans_roles=correct_span_positions(pred_spans_roles)\n","  pred_spans_status=correct_span_positions(pred_spans_status)\n","  pred_spans_method=correct_span_positions(pred_spans_method)\n","  #Generates span pairs from the predictive data, mapping entities to  Role, Status, and Method.\n","  relation_pairs=list(itertools.product(pred_spans_ent, pred_spans_roles))\n","  relation_pairs.extend(list(itertools.product(pred_spans_ent, pred_spans_status)))\n","  relation_pairs.extend(list(itertools.product(pred_spans_ent, pred_spans_method)))\n","  relation_pair_labels_dict = {key: 'No Relation' for key in relation_pairs}\n","  return pred_spans_ent,pred_spans_roles,pred_spans_status,pred_spans_method,relation_pair_labels_dict\n","def generate_relation_prediction_data(sentence,tokenizer_outputs,relation_pair_labels_dict):\n","  '''\n","  Reads relation pair label dict and generates relation data inputs.\n","  Maps token indices to offset positions and inserts span markers.\n","  Outputs: Relation data input list\n","  '''\n","  data_input_list=[]\n","  offset_mapping_list=tokenizer_outputs['offset_mapping']\n","  for pair,pair_label in relation_pair_labels_dict.items():\n","    entity_pos=[]\n","    entity_pos.append(offset_mapping_list[pair[0][1][0]][0])\n","    entity_pos.append(offset_mapping_list[pair[0][1][1]][1])\n","    entity_pos.append('entity')\n","    role_pos=[]\n","    role_pos.append(offset_mapping_list[pair[1][1][0]][0])\n","    role_pos.append(offset_mapping_list[pair[1][1][1]][1])\n","    role_pos.append('role')\n","\n","    marked_sentence = insert_span_markers(sentence,[entity_pos,role_pos])\n","    data_input_list.append({'text':marked_sentence,'Entity':pair[0][0],'Entity_pos':entity_pos,'Role':pair[1][0],'Role_pos':role_pos,'label':pair_label})\n","  return data_input_list\n","\n","def generate_relation_data(text,inputs,prediction_data_ent,prediction_data_role,prediction_data_status,prediction_data_method,id_label_ent,id_label_method,id_label_role,id_label_status,relation_labels=None):\n","  '''\n","  Generates relation data input list from the prediction data.\n","  Outputs: Relation data input list\n","  '''\n","  #inputs = tokenizer(text,max_length=max_len,truncation=True,return_offsets_mapping=True)\n","\n","  tokens_len=len(inputs['input_ids'])\n","  if tokens_len==len(prediction_data_ent):\n","    pred_spans_ent,pred_spans_roles,pred_spans_status,pred_spans_method,relation_pair_labels_dict=generate_prediction_spans(prediction_data_ent,prediction_data_role,prediction_data_status,prediction_data_method,id_label_ent,id_label_method,id_label_role,id_label_status)\n","    relation_data=generate_relation_prediction_data(text,inputs,relation_pair_labels_dict)\n","    return relation_data\n","  else:\n","    return None\n","def predict_relation(text):\n","  '''\n","  Predicts relation for a given text with the span markers.\n","  Outputs: Relation label for the given text\n","  '''\n","  rel_model.eval()\n","  inputs=tokenizer2(text, add_special_tokens=True, padding='max_length',max_length=max_len , truncation=True,return_tensors='pt')\n","  with torch.no_grad():\n","    inp={k: v.to(device) for k, v in inputs.items()}\n","    outputs = rel_model(**inp)\n","  logits = outputs.logits\n","  raw_predictions = torch.argmax(logits, dim=-1)\n","  prediction=id_label_event[raw_predictions.item()]\n","  return prediction\n"],"metadata":{"id":"t_CpP_2OufKV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertForSequenceClassification\n","tokenizer2=BertTokenizerFast.from_pretrained(rel_classifier_pth)\n","rel_model=BertForSequenceClassification.from_pretrained(rel_classifier_pth)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"69GjmYiZ-plE","executionInfo":{"status":"ok","timestamp":1707265957808,"user_tz":300,"elapsed":11357,"user":{"displayName":"srikaran elakurthy","userId":"10476685350926501647"}},"outputId":"4ef83ca7-7bb7-41b9-c769-7c07bc61df48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"markdown","source":["# Predicting entity relation"],"metadata":{"id":"glg3h3AbAn-p"}},{"cell_type":"code","source":["def predict_entity_relation(txt):\n","  '''\n","  Predicts entities,roles,status and method also establishes relation or not between them.\n","  '''\n","  inputs=tokenizer(txt,max_length=max_len,truncation=True,return_offsets_mapping=True,return_tensors='pt')\n","  model_input={'input_ids':inputs['input_ids'].to(device),'attention_mask':inputs['attention_mask'].to(device)}\n","  ner_model.eval()\n","  with torch.no_grad():\n","    status_logits, method_logits, role_logits, entity_logits=ner_model(**model_input)\n","    entity_probabilities = torch.softmax(entity_logits, dim=-1)\n","    entity_predictions = torch.argmax(entity_probabilities, dim=-1)\n","    role_probabilities  = torch.softmax(role_logits,dim=-1)\n","    role_predictions = torch.argmax(role_probabilities, dim =-1)\n","    status_probabilities=torch.softmax(status_logits,dim=-1)\n","    status_predictions=torch.argmax(status_probabilities,dim=-1)\n","\n","    method_probabilities=torch.softmax(method_logits,dim=-1)\n","    method_predictions=torch.argmax(method_probabilities,dim=-1)\n","    rel_dt_lst=generate_relation_data(txt,inputs,entity_predictions.tolist()[0],role_predictions.tolist()[0],status_predictions.tolist()[0],method_predictions.tolist()[0],id_label_ent,id_label_method,id_label_role,id_label_status)\n","    rel_df=pd.DataFrame(rel_dt_lst)\n","    rel_df['predict_relation']=rel_df['text'].apply(predict_relation)\n","  return rel_df\n"],"metadata":{"id":"OxVYX-F_--Ug"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_entity_relation(txt)"],"metadata":{"id":"cYBbq4xD_fZW"},"execution_count":null,"outputs":[]}]}